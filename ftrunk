#!/usr/bin/env python

import bz2
import hashlib
import hmac
import json
import os
import random
import sqlite3
import sys
import time

from Crypto.Cipher import AES
from argparse import ArgumentParser
from base64 import b64encode, b64decode
from multiprocessing import Pool
from tempfile import SpooledTemporaryFile


def checksum512(path, block_size=4096):
    try:
        sys.stdout.write('\033[K')
        sys.stdout.write('\rProcessing: [%s]' % path)
        sys.stdout.flush()
        with open(path, 'rb') as f:
            h = hashlib.sha512()
            s = 0
            for chunk in iter(lambda: f.read(block_size), b''):
                s += len(chunk)
                h.update(chunk)
        return h.hexdigest(), path, s
    except Exception:
        return None


class Ftrunk(object):

    def __init__(self, db_, src_, dst_):
        self.db = db_
        self.src = src_
        self.dst = dst_
        self.version = int(time.time())

        c = self.db.cursor()

        # trunk table for storing files/directories
        query = """CREATE TABLE IF NOT EXISTS trunk (
            hash TEXT,
            file TEXT,
            size INTEGER,
            version INTEGER,
            UNIQUE(hash, version) ON CONFLICT REPLACE
        )"""
        c.execute(query)

        # table for storing hash/passwords
        query = """CREATE TABLE IF NOT EXISTS hashes (
            hash TEXT,
            pass TEXT,
            UNIQUE(hash) ON CONFLICT REPLACE
        )"""
        c.execute(query)

        # config table
        query = """CREATE TABLE IF NOT EXISTS config (
            key TEXT,
            value TEXT,
            version INTEGER,
            PRIMARY KEY(key)
        )"""
        c.execute(query)

        c.executemany('INSERT OR REPLACE INTO config VALUES(?, ?, ?)',
                      [
                          ('src', self.src, self.version),
                          ('dst', self.dst, self.version)
                      ])

        #c.execute('SELECT EXISTS (SELECT 1 FROM trunk)')
        self.db.commit()

        # initialize the ftrunk
        self.trunk = {}

    def build(self):
        self.trunk['dirs'] = []
        self.trunk['files'] = {}

        def append_files(x):
            if x:
                f = self.trunk['files'].setdefault(x[0], [])
                if f:
                    f[0][0].append(x[1][len(self.src):])
                else:
                    f.append(([x[1][len(self.src):]], x[2]))

        # multiprocessing Pool (use all the cores)
        pool = Pool()

        # reading src
        for root, dirs_o, files_o in os.walk(self.src):
            for d in dirs_o:
                self.trunk['dirs'].append(
                    (os.path.join(root, d)[len(self.src):], None, 0))
            for f in files_o:
                file_path = os.path.join(root, f)
                if os.path.isfile(file_path):
                    pool.apply_async(
                        checksum512,
                        args=(file_path,),
                        callback=append_files)

        # wait until all process finish
        pool.close()
        pool.join()

        # trunk files structure
        # hash, list of file or files, size
        self.trunk['files'] = [(k, json.dumps(v[0][0]), v[0][1])
                               for k, v in self.trunk['files'].iteritems()]

    def backup(self, filename, filehash):
        """encrypt filename and save it on the backup dir
        if success
            return base64(password)
        else:
            return None
        """
        if not os.path.isfile(filename):
            print 'Not a file'
            return

        backup_dir = os.path.join(
            self.dst,
            filehash[:2],
            filehash[2:4],
            filehash[4:6])

        backup_file_path = os.path.join(backup_dir, filehash)

        if os.path.isfile(backup_file_path):
            return

        # create the backup_dir
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)

        try:
            with open(filename, 'rb') as in_file:
                with SpooledTemporaryFile(suffix='.tmp', dir=self.dst) \
                        as tmp_file:
                    compressor = bz2.BZ2Compressor(9)
                    for chunk in iter(lambda: in_file.read(4096), b''):
                        tmp_file.write(compressor.compress(chunk))
                    tmp_file.write(compressor.flush())

                    with open(backup_file_path, 'wb') as out_file:
                        try:
                            return self.encrypt(tmp_file, out_file)
                        except Exception as e:
                            print e
        except Exception as e:
            print e
            return

    def encrypt(self, in_file, out_file):
        # out_file: iv + AES encrypted file
        aes_key = os.urandom(32)
        iv = ''.join(chr(random.randint(0, 0xFF)) for i in range(16))
        chiper = AES.new(aes_key, AES.MODE_CBC, iv)
        BS = AES.block_size
        out_file.write(iv)
        in_file.seek(0)
        sig = hmac.new(aes_key, iv, digestmod=hashlib.sha1)
        pad = lambda s: s + (BS - len(s) % BS) * chr(BS - len(s) % BS)
        for chunk in iter(lambda: in_file.read(1024 * BS), b''):
            chunk = pad(chunk)
            chunk = chiper.encrypt(chunk)
            sig.update(chunk)
            out_file.write(chunk)
        return b64encode(aes_key + sig.digest())

    def decrypt(self, key, in_filename, out_filename):
        with open(in_filename) as in_file:
            decoded_key = b64decode(key)
            aes_key = decoded_key[:32]
            expected_sig = decoded_key[32:]
            BS = AES.block_size
            iv = in_file.read(BS)
            sig = hmac.new(aes_key, iv, digestmod=hashlib.sha1)
            cipher = AES.new(aes_key, AES.MODE_CBC, iv)
            unpad = lambda s: s[:-ord(s[-1])]
            with open(out_filename, 'wb') as out_file:
                for chunk in iter(lambda: in_file.read(1024 * BS), b''):
                    sig.update(chunk)
                    chunk = cipher.decrypt(chunk)
                    out_file.write(unpad(chunk))
                # if not hmac.compare_digest(expected_sig, sig.digest()):
                if expected_sig != sig.digest():
                    raise ValueError('Bad file signature!')

    def save_trunk(self, data):
        c = self.db.cursor()
        query = """INSERT INTO trunk(
            hash,
            file,
            size,
            version
        ) VALUES(?, ?, ?, %s)""" % (self.version)
        c.executemany(query, data)
        return self.db.commit()

    def save_password(self, key_hash, password):
        c = self.db.cursor()
        c.execute(
            'INSERT OR REPLACE INTO hashes VALUES(?, ?)',
            (key_hash, password))
        return self.db.commit()


if __name__ == '__main__':
    start_time = time.time()

    parser = ArgumentParser(description="create or restore file trunks")
    parser.add_argument(
        'name',
        help='name of the file trunk')
    parser.add_argument(
        '-s', action='store', dest='src',
        help='source directory containing files to be backed or *.frunk file \
to be restored when using option -r')
    parser.add_argument(
        '-d', action='store', dest='dst',
        help='destination directory where the backup will be written \
or restored when using option -r')
    parser.add_argument(
        '-r', '--restore', action='store', dest='version',
        help='restore backup')
    parser.add_argument(
        '-v', '--versions', action='store_true',
        help='list versions (stored backups))')

    args = parser.parse_args()

    name = args.name.split()[0]
    trunks = os.path.expanduser('~/.ftrunk')
    if not os.path.isdir(trunks):
        os.mkdir(trunks, 0o700)

    db = os.path.join(trunks, '%s.ftrunk' % name)
    db = sqlite3.connect(db)
    db.text_factory = lambda x: unicode(x, 'utf-8', 'ignore')

    _c = db.cursor()

    # if ftrunk database exists, try to use it and just backup new files
    # without need to specify src, dst
    try:
        _c.execute('SELECT value FROM config where key="src"')
        src = _c.fetchone()[0]
        _c.execute('SELECT value FROM config where key="dst"')
        dst = _c.fetchone()[0]
    except Exception as e:
        src = dst = None
        if not args.src or not args.dst:
            exit('-s source and -d destination are required')

    # just print the versions and exit
    if args.versions:
        print '+----------------------------------+'
        print '| Version    | Created on (UTC)    |'
        print '+----------------------------------+'
        for row in _c.execute('SELECT DISTINCT(version), \
                datetime(version, "unixepoch", "UTC") FROM trunk \
                ORDER BY 1 DESC'):
            print '| %s | %s |' % (row[0], row[1])
        print '+----------------------------------+'
        exit()

    # set src using -s arg or use the existing one declared on the
    # trunk db
    if args.src:
        args.src = os.path.abspath(os.path.expanduser(args.src))
        if src and src != args.src:
            exit('Trunk already exists')
        src = args.src

    # check that src dir exists
    if not os.path.isdir(src):
        exit('%s - Source directory does not exists' % src)

    # set dst using -d arg or use the existing one declared on the trunk db
    # multiple destinations are supported
exit('fix this')
    if args.dst:
        dst = os.path.abspath(os.path.expanduser(args.dst))

    # check that dst dir exists
    if not os.path.isdir(dst):
        if not os.path.isdir(os.path.abspath(os.path.join(dst, os.pardir))):
            exit('%s - Destination directory does not exists' % dst)
        os.mkdir(dst, 0o700)

    if args.version:
        _c.execute('SELECT DISTINCT(version) FROM trunk WHERE version=?',
                   (args.version,))
        try:
            if _c.fetchone()[0]:
                print 'ja quase'
        except Exception:
            exit('version not found try using -v to list available versions')
        exit('---- restore ---- pending')

    ft = Ftrunk(db, src, dst)
    ft.build()
    ft.save_trunk(ft.trunk['dirs'] + ft.trunk['files'])

    total_files = len(ft.trunk['files'])
    for f_ in ft.trunk['files']:
        total_files -= 1
        f_hash, f_list, f_size = f_
        if f_size:
            f_list = json.loads(f_list)

            # print percentage and working file
            percent = 100 - (total_files * 100) / len(ft.trunk['files'])
            sys.stdout.write('Backing up: %d%% [%s]\r' % (percent, f_list[0]))
            sys.stdout.flush()

            # encrypt and backup the file
            psw = ft.backup(
                os.path.join(ft.src, f_list[0].lstrip(os.sep)),
                f_hash)

            if psw:
                ft.save_password(f_hash, psw)

    # Erase to end of line
    sys.stdout.write('Finished.\033[K')
    sys.stdout.flush()

    print '\n' + 'Elapsed time: ' + str(time.time() - start_time)
